{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/media/tupv8/32f7b466-e4d4-4f6f-b2aa-1e5a8ce7663c/vinai/reproduce/model/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from hfnet.evaluation.keypoint_detectors import compute_average_precision, compute_correctness, compute_pr\n",
    "from hfnet.evaluation.utils.keypoints import keypoints_warp_2D\n",
    "from hfnet.evaluation.utils.misc import div0\n",
    "import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from hfnet.dataset.hpatches import HpatchesDataset\n",
    "\n",
    "\n",
    "from hfnet.model import HFNet\n",
    "\n",
    "from hfnet import prediction\n",
    "from hfnet import evaluation\n",
    "from hfnet.export_local import export_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = HpatchesDataset(alteration='all', make_pairs=True, shuffle=True)\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "mode_config= {\n",
    "        'loss_weights': 'uncertainties',\n",
    "        'local_head': {\n",
    "            'descriptor_dim': 256,\n",
    "            'detector_grid': 8,\n",
    "            'input_channels': 96\n",
    "        },\n",
    "        'global_head': {\n",
    "            'n_clusters': 32,\n",
    "            'intermediate_proj': 0,\n",
    "            'dimensionality_reduction': 4096\n",
    "        }\n",
    "}\n",
    "model = HFNet(config= mode_config,width_mult=0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPER_PATH = '/media/tupv8/32f7b466-e4d4-4f6f-b2aa-1e5a8ce7663c/vinai/reproduce/model/'\n",
    "\n",
    "models = { \n",
    "    'silk':{\n",
    "        'binary_cross_entropy' : 'silk/111/binary_cross_entropy/last_model.pth',\n",
    "        'cross_entropy': 'silk/111/cross_entropy/last_model.pth',\n",
    "    }\n",
    "}\n",
    "\n",
    "config = {\n",
    "    'hfnet':{\n",
    "        'local':{\n",
    "            'nms_radius':4,\n",
    "            'detector_threshold': 0.005,\n",
    "            'num_keypoints': 1000,\n",
    "        },\n",
    "        'num_features': 300,\n",
    "        # 'do_nms': True,\n",
    "        # 'nms_thresh': 4,\n",
    "        # 'remove_borders': 4,\n",
    "    },\n",
    "    'do_ratio_test': False,\n",
    "    'correct_match_thresh': 3,\n",
    "    'correct_H_thresh': 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, config):\n",
    "    num_kpts = []\n",
    "    loc_error = []\n",
    "    repeatability = []\n",
    "    all_tp = []\n",
    "    all_num_gt = 0\n",
    "    all_scores = []\n",
    "\n",
    "    for data in tqdm.tqdm(dataloader):\n",
    "        \n",
    "        shape1 = data['image'].detach().cpu().numpy().shape[-2:][::-1]  # (height, width) -> (width, height)\n",
    "        shape2 = data['image2'].detach().cpu().numpy().shape[-2:][::-1]  # modifiy\n",
    "\n",
    "        #print(shape1,shape2)\n",
    "\n",
    "        pred1 = export_loader(model(data['image'].unsqueeze(0)), config['hfnet'], data['image'].squeeze(0))\n",
    "        pred2 = export_loader(model(data['image2'].unsqueeze(0)), config['hfnet'], data['image2'].squeeze(0))\n",
    "\n",
    "\n",
    "        num_kpts.extend([len(pred1['keypoints']), len(pred2['keypoints'])])\n",
    "        if len(pred1['keypoints']) == 0 or len(pred2['keypoints']) == 0:\n",
    "            repeatability.append(0)\n",
    "            continue\n",
    "        H = data['homography'][0]\n",
    "        #print(H)\n",
    "        kpts1_w, vis1 = keypoints_warp_2D(\n",
    "            pred1['keypoints'], np.linalg.inv(H), shape2)\n",
    "        kpts2_w, vis2 = keypoints_warp_2D(\n",
    "            pred2['keypoints'], H, shape1)\n",
    "\n",
    "\n",
    "        correct1, correct2, dist1, dist2 = compute_correctness(\n",
    "            pred1['keypoints'], pred2['keypoints'], kpts1_w, kpts2_w,\n",
    "            config['correct_match_thresh'])\n",
    "\n",
    "        error1 = dist1[vis1 & correct1]\n",
    "        if len(error1) > 0:\n",
    "            loc_error.append(error1.mean())\n",
    "        error2 = dist2[vis2 & correct2]\n",
    "        if len(error2) > 0:\n",
    "            loc_error.append(error2.mean())\n",
    "\n",
    "        repeat = div0(correct1[vis1].sum() + correct2[vis2].sum(),\n",
    "                        vis1.sum() + vis2.sum())\n",
    "        repeatability.append(repeat)\n",
    "\n",
    "        all_tp.extend([correct1[vis1], correct2[vis2]])\n",
    "        all_scores.extend([pred1['scores'][vis1], pred2['scores'][vis2]])\n",
    "        all_num_gt += vis2.sum() + vis1.sum()\n",
    "\n",
    "    precision, recall, scores = compute_pr(\n",
    "        np.concatenate(all_tp, 0), np.concatenate(all_scores, 0), all_num_gt,\n",
    "        reverse=True)  # confidence is in decreasing order\n",
    "    mAP = compute_average_precision(precision, recall)\n",
    "\n",
    "    metrics = {\n",
    "        'average_num_keypoints': np.mean(num_kpts),\n",
    "        'localization_error': np.mean(loc_error),\n",
    "        'repeatability': np.mean(repeatability),\n",
    "        'mAP': mAP,\n",
    "    }\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint: batch 1\n",
      "{'hfnet': {'local': {'nms_radius': 4, 'detector_threshold': 0.005, 'num_keypoints': 1000}, 'num_features': 300}, 'do_ratio_test': False, 'correct_match_thresh': 3, 'correct_H_thresh': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 580/580 [09:51<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-20 10:34:00\n",
      "average_num_keypoints     300.000\n",
      "localization_error        1.580\n",
      "repeatability             0.217\n",
      "mAP                       0.064\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "for k,v in models.items():\n",
    "    for kk,vv in v.items():\n",
    "        print(f\"{k}: {kk}\")\n",
    "        print(config)\n",
    "        state_dict = torch.load(EXPER_PATH + vv, weights_only= False ,map_location=device)\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "        metrics=evaluate(model, dataloader, config)\n",
    "        \n",
    "\n",
    "        current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "        print(current_time)\n",
    "\n",
    "        log_file = open('detector.txt', 'a')\n",
    "        log_file.write('\\n[{}]'.format(current_time))\n",
    "        log_file.write('\\n{}: {}'.format(k, kk))\n",
    "        log_file.write('{}\\n'.format(config))\n",
    "\n",
    "\n",
    "        for km, vm in metrics.items():\n",
    "                print('{:<25} {:.3f}'.format(km, vm))\n",
    "\n",
    "                #save in log file\n",
    "                log_file.write('{:<25} :{:.3f}  '.format(km, vm))\n",
    "                log_file.write('\\n')\n",
    "        log_file.flush()\n",
    "        print(\"-----------------------------------\")\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reproduce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
